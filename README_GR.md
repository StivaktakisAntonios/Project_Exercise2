# Neural LSH - Προσεγγιστική Αναζήτηση Πλησιέστερων Γειτόνων

**Έργο:** Κ23γ – 2η Προγραμματιστική Εργασία  
**Μάθημα:** Ανάπτυξη Λογισμικού για Αλγοριθμικά Προβλήματα  
**Εξάμηνο:** Χειμερινό 2025-26

**Ομάδα 15:**  
- **Ανέστης Θεοδωρίδης** – ΑΜ: 1115201500212 – Email: sdi1500212@di.uoa.gr
- **Αντώνιος-Ραφαήλ Στιβακτάκης** – ΑΜ: 1115202200258 – Email: sdi2200258@di.uoa.gr

---

## Περιγραφή

Υλοποίηση του αλγορίθμου Neural LSH (Locality-Sensitive Hashing) για προσεγγιστική αναζήτηση πλησιέστερων γειτόνων χρησιμοποιώντας διαμέριση βασισμένη σε νευρωνικά δίκτυα.

Ο αλγόριθμος συνδυάζει:
- Κατασκευή γράφου k-NN για ανάλυση της δομής του συνόλου δεδομένων
- Ισοκατανεμημένη διαμέριση γράφου με χρήση KaHIP
- Εκπαίδευση ταξινομητή MLP (Multi-Layer Perceptron) για πρόβλεψη διαμερισμάτων
- Στρατηγική multi-probe search για αποδοτική αναζήτηση

Η υλοποίηση ακολουθεί τις προδιαγραφές της 2ης Εργασίας και παράγει έξοδο συμβατή με τις μεθόδους της 1ης Εργασίας (LSH, Hypercube, IVFFlat, IVFPQ) για άμεση σύγκριση απόδοσης.

**Σημείωση για την κατασκευή k-NN γράφου:** Η τρέχουσα υλοποίηση χρησιμοποιεί brute-force υπολογισμό Ευκλείδειας απόστασης. Για βέλτιστη απόδοση σε μεγάλα σύνολα δεδομένων, μπορεί να ενσωματωθούν οι βελτιστοποιημένες μέθοδοι της 1ης Εργασίας (π.χ. LSH ή IVF-based προσεγγιστική k-NN) ως βήμα προεπεξεργασίας.

## Δομή Έργου

```
Project_Exercise2/
├── Exercise/
│   ├── Modules/              # Βασικές ενότητες υλοποίησης
│   │   ├── config.py         # Ρυθμίσεις και σταθερές
│   │   ├── dataset_parser.py # Φόρτωση δεδομένων (MNIST, SIFT)
│   │   ├── graph_utils.py    # Κατασκευή γράφου k-NN
│   │   ├── partitioner.py    # Διαμέριση γράφου με KaHIP
│   │   ├── models.py         # Εκπαίδευση ταξινομητή MLP
│   │   ├── index_io.py       # Αποθήκευση/φόρτωση ευρετηρίου
│   │   └── search.py         # Αλγόριθμοι αναζήτησης
│   └── NeuralLSH/           # Εργαλεία γραμμής εντολών
│       ├── nlsh_build.py    # Script κατασκευής ευρετηρίου
│       └── nlsh_search.py   # Script αναζήτησης ερωτημάτων
├── experiments/             # Πειραματική επικύρωση
│   ├── run_experiments.py  # Αυτοματοποιημένη εκτέλεση πειραμάτων
│   └── results/            # Αποτελέσματα πειραμάτων
├── Raw_Data/               # Σύνολα δεδομένων εισόδου
│   ├── MNIST/
│   └── SIFT/
└── requirements.txt        # Εξαρτήσεις Python
```

## Εγκατάσταση

### Προαπαιτούμενα

- Python 3.10 ή νεότερο
- Εργαλείο διαμέρισης γράφων KaHIP

### Οδηγίες Εγκατάστασης

1. Κλωνοποίηση του αποθετηρίου:
```bash
git clone <repository-url>
cd Project_Exercise2
```

2. Δημιουργία και ενεργοποίηση εικονικού περιβάλλοντος:
```bash
python3 -m venv .venv
source .venv/bin/activate  # Σε Linux/Mac
```

3. Εγκατάσταση εξαρτήσεων Python:
```bash
pip install -r requirements.txt
```

4. Εγκατάσταση KaHIP:
```bash
# Αυτόματη εγκατάσταση
./install_kahip.sh

# Ή χειροκίνητα - δείτε το INSTALL_KAHIP.md για οδηγίες
```

5. Επαλήθευση εγκατάστασης:
```bash
which kaffpa
python -c "import torch; print(torch.__version__)"
```

## Χρήση

### Κατασκευή Ευρετηρίου

Δημιουργία ευρετηρίου Neural LSH από ένα σύνολο δεδομένων:

```bash
python Exercise/NeuralLSH/nlsh_build.py \
    -d Raw_Data/MNIST/input.idx3-ubyte \
    -i indices/mnist_index \
    -type mnist \
    --knn 10 \
    -m 100 \
    --epochs 10
```

**Υποχρεωτικές Παράμετροι:**
- `-d, --dataset`: Διαδρομή αρχείου συνόλου δεδομένων
- `-i, --index`: Διαδρομή καταλόγου εξόδου ευρετηρίου
- `-type`: Τύπος δεδομένων (`mnist` ή `sift`)

**Προαιρετικές Παράμετροι:**
- `--knn`: Αριθμός πλησιέστερων γειτόνων για κατασκευή γράφου (προεπιλογή: 10)
- `-m, --partitions`: Αριθμός διαμερισμάτων/bins (προεπιλογή: 100)
- `--max_points`: Μέγιστος αριθμός σημείων για γράφο k-NN (προεπιλογή: όλα). Χρήση για μεγάλα datasets όπως SIFT
- `--imbalance`: Ανοχή ανισορροπίας KaHIP (προεπιλογή: 0.03)
- `--kahip_mode`: Λειτουργία KaHIP: 0=FAST, 1=ECO, 2=STRONG (προεπιλογή: 2)
- `--layers`: Αριθμός κρυφών επιπέδων MLP (προεπιλογή: 3)
- `--nodes`: Πλάτος κρυφού επιπέδου MLP (προεπιλογή: 64)
- `--epochs`: Περίοδοι εκπαίδευσης (προεπιλογή: 10)
- `--batch_size`: Μέγεθος δέσμης εκπαίδευσης (προεπιλογή: 128)
- `--lr`: Ρυθμός εκμάθησης (προεπιλογή: 0.001)
- `--seed`: Σπόρος τυχαιότητας για αναπαραγωγιμότητα (προεπιλογή: 1)

### Αναζήτηση σε Ευρετήριο

Αναζήτηση πλησιέστερων γειτόνων χρησιμοποιώντας κατασκευασμένο ευρετήριο:

```bash
python Exercise/NeuralLSH/nlsh_search.py \
    -d Raw_Data/MNIST/input.idx3-ubyte \
    -q Raw_Data/MNIST/query.idx3-ubyte \
    -i indices/mnist_index \
    -o results/mnist_output.txt \
    -type mnist \
    -N 10 \
    -T 5 \
    -R 2000
```

**Υποχρεωτικές Παράμετροι:**
- `-d, --dataset`: Διαδρομή αρχείου συνόλου δεδομένων
- `-q, --query`: Διαδρομή αρχείου ερωτημάτων
- `-i, --index`: Διαδρομή καταλόγου ευρετηρίου
- `-o, --output`: Διαδρομή αρχείου εξόδου αποτελεσμάτων
- `-type`: Τύπος δεδομένων (`mnist` ή `sift`)

**Προαιρετικές Παράμετροι:**
- `-N`: Αριθμός πλησιέστερων γειτόνων προς επιστροφή (προεπιλογή: 1)
- `-R`: Ακτίνα για R-near neighbors (προεπιλογή: 2000 για MNIST, 2800 για SIFT)
- `-T, --top_bins`: Αριθμός κορυφαίων bins προς έλεγχο (προεπιλογή: 5)
- `-range`: Υπολογισμός R-near neighbors: true ή false (προεπιλογή: true)
- `--max_queries`: Περιορισμός αριθμού ερωτημάτων (προεπιλογή: όλα). Χρήση για γρήγορες δοκιμές

### Εκτέλεση Πειραμάτων

Εκτέλεση προκαθορισμένων πειραμάτων:

```bash
# Πείραμα MNIST
python experiments/run_experiments.py --dataset mnist

# Πείραμα SIFT
python experiments/run_experiments.py --dataset sift

# Όλα τα πειράματα
python experiments/run_experiments.py --all
```

## Αλγοριθμική Ροή

### Κατασκευή Ευρετηρίου

1. **Φόρτωση Συνόλου Δεδομένων**: Ανάγνωση δεδομένων εισόδου (μορφή MNIST ή SIFT)
2. **Κατασκευή Γράφου k-NN**: Δημιουργία προσεγγιστικού γράφου k-NN με χρήση brute-force αναζήτησης
3. **Διαμέριση Γράφου**: Χρήση KaHIP για δημιουργία ισοκατανεμημένων διαμερισμάτων του γράφου k-NN
4. **Εκπαίδευση Ταξινομητή**: Εκπαίδευση MLP για πρόβλεψη αναθέσεων διαμερισμάτων από σημεία δεδομένων
5. **Αποθήκευση Ευρετηρίου**: Διατήρηση inverted index, εκπαιδευμένου μοντέλου και μεταδεδομένων

### Αναζήτηση Ερωτημάτων

1. **Φόρτωση Ευρετηρίου**: Φόρτωση inverted index και εκπαιδευμένου ταξινομητή
2. **Πρόβλεψη Διαμερισμάτων**: Χρήση MLP για πρόβλεψη των T πιο πιθανών bins για κάθε ερώτημα
3. **Multi-Probe Search**: Αναζήτηση υποψηφίων από επιλεγμένα bins
4. **Επανατοποθέτηση**: Υπολογισμός ακριβών αποστάσεων και επιστροφή των N πλησιέστερων γειτόνων

## Ρυθμίσεις

Βασικές παράμετροι στο `Exercise/Modules/config.py`:

```python
DEVICE = "cpu"          # Επιβολή εκτέλεσης μόνο σε CPU
RANDOM_SEED = 1         # Προεπιλεγμένος σπόρος τυχαιότητας
EPSILON = 1e-10         # Σταθερά αριθμητικής σταθερότητας
```

## Μορφές Συνόλων Δεδομένων

### MNIST
- Μορφή: IDX3-ubyte (δυαδική μορφή με 4-byte header)
- Διαστάσεις: 784 (28×28 pixels)
- Είσοδος: `Raw_Data/MNIST/input.idx3-ubyte`
- Ερωτήματα: `Raw_Data/MNIST/query.idx3-ubyte`

### SIFT
- Μορφή: fvecs (δυαδική μορφή με 4-byte πρόθεμα διάστασης)
- Διαστάσεις: 128
- Βάση: `Raw_Data/SIFT/sift_base.fvecs`
- Ερωτήματα: `Raw_Data/SIFT/sift_query.fvecs`
- Ground truth: `Raw_Data/SIFT/sift_groundtruth.ivecs`

## Μορφή Εξόδου

Τα αποτελέσματα αναζήτησης γράφονται στη μορφή:

```
METHOD NAME: Neural LSH
Neural LSH
Query: 0
Nearest neighbor-1: 123
distanceApproximate: 45.67
distanceTrue: 45.23
...
Nearest neighbor-N: 456
distanceApproximate: 67.89
distanceTrue: 67.45
R-near neighbors:
789
...
Average AF: 1.0234
Recall@N: 0.9567
QPS: 123.45
tApproximateAverage: 0.00123
tTrueAverage: 0.45678
```

Κάθε γραμμή περιέχει IDs γειτόνων χωρισμένα με κενά (0-indexed) για ένα μεμονωμένο ερώτημα.

## Βελτιστοποίηση Απόδοσης

### Κατασκευή Ευρετηρίου
- **Περισσότερα διαμερίσματα** (`-m`): Καλύτερη επιλεκτικότητα αλλά περισσότερη αποθήκευση
- **Υψηλότερο k** (`--knn`): Καλύτερη ποιότητα γράφου αλλά πιο αργή κατασκευή
- **Περισσότερες περίοδοι**: Καλύτερος ταξινομητής αλλά μεγαλύτερος χρόνος εκπαίδευσης
- **Ισχυρότερη λειτουργία KaHIP**: Καλύτερα διαμερίσματα αλλά πιο αργή διαμέριση
- **max_points**: Χρήση για γρήγορες δοκιμές σε μεγάλα datasets

### Αναζήτηση Ερωτημάτων
- **Περισσότερα bins** (`-T`): Υψηλότερο recall αλλά πιο αργή αναζήτηση
- **max_queries**: Χρήση για γρήγορη επικύρωση κατά την ανάπτυξη

## Δοκιμές

Εκτέλεση unit tests:

```bash
python Exercise/Modules/test_dataset_parser.py
python Exercise/Modules/test_graph_utils.py
python Exercise/Modules/test_models.py
```

## Σημειώσεις Ανάπτυξης

- **Μόνο CPU**: Η υλοποίηση χρησιμοποιεί PyTorch μόνο για CPU (δεν απαιτείται GPU)
- **Ντετερμινιστική**: Σταθεροί σπόροι τυχαιότητας εξασφαλίζουν αναπαραγώγιμα αποτελέσματα
- **Αποδοτική μνήμη**: Επεξεργασία σε δέσμες για μεγάλα σύνολα δεδομένων
- **Αρθρωτός σχεδιασμός**: Σαφής διαχωρισμός μεταξύ modules για συντηρησιμότητα
- **Συμβατότητα με Εργασία 1**: Η μορφή εξόδου ταιριάζει με την Εργασία 1 για άμεση σύγκριση με LSH, Hypercube, IVFFlat και IVFPQ

## Πειραματική Σύγκριση

Για την πειραματική αναφορά σύγκρισης του Neural LSH με τις μεθόδους της Εργασίας 1:

1. **Εκτέλεση πειραμάτων Neural LSH**:
   ```bash
   python experiments/run_experiments.py --all
   ```

2. **Σύγκριση μετρικών** (από αμφότερες τις εργασίες):
   - Recall@N: Κλάσμα αληθινών γειτόνων που βρέθηκαν
   - Average AF: Συντελεστής προσέγγισης (λόγος απόστασης)
   - QPS: Ερωτήματα ανά δευτερόλεπτο (throughput)
   - tApproximate: Μέσος χρόνος ερωτήματος
   - tTrue: Μέσος χρόνος υπολογισμού ground truth

3. **Βελτιστοποίηση υπερπαραμέτρων**: Χρήση `experiments/configs/` για δοκιμή διαφορετικών ρυθμίσεων:
   - Αριθμός διαμερισμάτων (`m`)
   - Μέγεθος γράφου k-NN (`k`)
   - Αρχιτεκτονική MLP (`layers`, `nodes`)
   - Παράμετροι εκπαίδευσης (`epochs`, `batch_size`, `lr`)
   - Βάθος multi-probe (`T`)

Τα αποτελέσματα θα αποθηκευτούν στο `experiments/results/` ως αρχεία JSON για ανάλυση.

## Αντιμετώπιση Προβλημάτων

### Δεν βρέθηκε το KaHIP
```bash
which kaffpa
export PATH=$PATH:/path/to/KaHIP/deploy
```

### Ανεπαρκής μνήμη
- Μείωση μεγέθους δέσμης: `--batch_size 64`
- Μείωση διαμερισμάτων: `-m 50`
- Χρήση μικρότερου k: `--knn 5`
- Περιορισμός σημείων: `--max_points 10000`

### Χαμηλό recall
- Αύξηση ελεγχόμενων bins: `-T 10`
- Χρήση περισσότερων διαμερισμάτων: `-m 200`
- Μεγαλύτερη εκπαίδευση: `--epochs 20`

### Αργή εκτέλεση κατά την ανάπτυξη
- Χρήση `--max_points` στο build: `--max_points 5000`
- Χρήση `--max_queries` στο search: `--max_queries 500`

## Αναφορές

- KaHIP: https://github.com/KaHIP/KaHIP
- PyTorch: https://pytorch.org/
